{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib\n",
    "numpy\n",
    "scikit-learn>=0.21.0\n",
    "seldon-core\n",
    "tornado>=6.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "import joblib\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(message)s')\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.model_file = \"trained_svm.dat\"\n",
    "    \n",
    "    def preprocess(self):\n",
    "        data = load_iris()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'])\n",
    "        self.train_data = (X_train, y_train)\n",
    "        self.test_data = (X_test, y_test)\n",
    "        \n",
    "    def train(self):\n",
    "        logging.info(\"Training SVM\")\n",
    "        self.preprocess()\n",
    "        model = SVC(gamma='auto')\n",
    "        model.fit(self.train_data[0], self.train_data[1])\n",
    "        logging.info(\"Model accuracy: %.2f\", model.score(self.test_data[0], self.test_data[1]))\n",
    "        joblib.dump(model, self.model_file)\n",
    "        logging.info(\"Model saved as: %s\", self.model_file)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        model = joblib.load(self.model_file)\n",
    "        return model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string\n",
    "HASH = ''.join([random.choice(string.ascii_lowercase) for n in range(16)] + [random.choice(string.digits) for n in range(16)])\n",
    "AWS_REGION = 'eu-west-1'\n",
    "!aws s3 mb s3://{HASH}'-kubeflow-pipeline-data' --region $AWS_REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kubeflow-fairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eval $(aws ecr get-login --no-include-email --region=$AWS_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow import fairing\n",
    "\n",
    "AWS_ACCOUNT_ID = fairing.cloud.aws.guess_account_id()\n",
    "DOCKER_REGISTRY = '{}.dkr.ecr.{}.amazonaws.com'.format(AWS_ACCOUNT_ID, AWS_REGION)\n",
    "S3_BUCKET = f'{HASH}-kubeflow-pipeline-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.fairing.builders.cluster.s3_context import S3ContextSource\n",
    "from kubeflow.fairing.backends import KubeflowAWSBackend\n",
    "\n",
    "import importlib\n",
    "\n",
    "BuildContext = S3ContextSource(\n",
    "    aws_account=AWS_ACCOUNT_ID, region=AWS_REGION,\n",
    "    bucket_name=S3_BUCKET\n",
    ")\n",
    "\n",
    "backend = KubeflowAWSBackend(build_context_source=BuildContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.fairing import TrainJob\n",
    "\n",
    "train_job = TrainJob(SVMClassifier, input_files=[\"requirements.txt\"],\n",
    "                     docker_registry=DOCKER_REGISTRY,\n",
    "                     backend=backend)\n",
    "train_job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $S3_BUCKET --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 rb s3://$S3_BUCKET --force\n",
    "!aws ecr delete-repository --repository-name fairing-job --region $AWS_REGION --force"
   ]
  }
 ]
}